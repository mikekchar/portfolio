---
layout: default
title: What is Quality?
permalink: Quality
category: Agile
description: Quality is job number 1, but what does that mean for software?
summary:  A recent release of Ubuntu software fails to meet the quality expectations of a popular podcast host. This brings up the question. What does quality really mean for software?  What can organizations do to reduce quality issues on release?
---
## Let's Not Surprise the User.

I admit that I have a soft spot for the podcast 
[Linux Outlaws](http://sixgun.org/linuxoutlaws/).  It's not a terribly
technical podcast, but it fills it's niche well and it's entertaining.
In a [recent episode](http://sixgun.org/linuxoutlaws-280/) one of
the hosts, Fab, goes on a rant about the quality level of
[Ubuntu](http://www.ubuntu.com/)'s latest software release.
Previously Canonical's Mark Shuttleworth had apparently promised that
the focus for this release would be quality (I think
[this](http://www.markshuttleworth.com/archives/1121) is the
blog posting that Fab was referring to).  Fab feels that
Canonical fell short of the mark.

What I find most interesting about the situation is the contrast
between Mark Shuttleworth's blog posting and Fab's rant.  Where
Shuttleworth speaks about activities they undergo to ensure
quality, Fab complains about the end product not working the
way he expects.  To me this is a classic disconnect that many
companies have: they define quality in terms of process or tools,
while the consumer defines quality in terms of the product meeting
expectations.

### A Definition of "Quality"

In an earlier posting on 
[Requirements and Expectations](..\RequirementsAndExpectations)
I discussed the difference between a requirement necessary to deploy
and an expectation that a user may have.  If you do not fulfill
a requirement, you can not deploy the system.  However, even if
a requirement has been met, the user may still be disappointed.
This is a quality issue.

I would like to offer the following definition of quality:  Quality
is the degree to which the users' expectations are met.  Please note that
a failure to meet *developers' expectations* is not a quality issue
unless the users also have the same expectations.  Even failure
to meet a requirement may not be a quality issue if the users do
not expect that functionality.  This might occur if there is
a requirement necessary for generating revenue for the company, but
which doesn't impact the user using the product.

Quality is obviously a subjective measure.  All users have different
expectations.  Usually internal testing is not sufficient to determine
the level of quality in a product.  The way a user reacts to a set
of features may very well be different from the way an internal
QA team reacts.  For an organization that is determined to have achieve
a very high level of quality, it is imperitive to seek an opinion
from a representative sample of users.  In other other industries
this is known as a focus group.  The same can be achieved in software
with a beta test, but special attention must be made to measure
the user's reactions to the product.

### Ensuring Quality

Ensuring quality is probably one of the most difficult aspects of
managing software releases.  Very often the responsibility for
ensuring quality in a product is delegated to a separate "Quality
Assurance Team".  The idea is that this team will inspect what
has been created and catch defects before they are released.
(Note that a defect may not be a quality issue unless it affects
user expectations.  But that is a topic for another post).

Fab's excellent description of his view of the problems in
the Ubuntu release illustrates why we can't rely simply on QA
teams.  To take an example, he describes a feature where
the user is presented with suggestions for products when searching
on the destop.  The quality issue he raises is that the feature
may make inappropriate suggestions (such as for pornography)
when the users is simply looking for an application that is on
their computer.  This feature was improved, but still failed
to meet Fab's expectations by release time.

The failure here is not on the QA side.  The feature undoubtedly 
met requirements when developed.  Although there is clearly
an error in the requirements, I personally wouldn't say the
root cause of the issue is in requirements gathering.  Instead,
the fault lies in prioritisation.  Requirements gathering
can never be 100% successful up front.  The problem was that
the risk of failure was underestimated and there was insufficient
time left in the development cycle to repair the problem.

### Prioritisation is Job Number One

As evidenced by the fact that the feature was not withdrawn even
though it contained quality issues, this feature was deemed to be
a requirement of release.  As such, it must be given a high enough
priority on the development schedule so that it can be viewed
early by users.  Because the risk of failure was also very high,
this should have been one of the very first features to be tested
by users.  On the contrary, it seems to have been one of the last.

Although it won't solve every problem, in my mind proper prioritization
goes a long way in reducing quality issues.  In fact, of all the
agile practices affecting quality, it is my opinion that something like
XP's "Planning Game" or Scrum's "Planning Poker" is the most important
practice for improving quality.

